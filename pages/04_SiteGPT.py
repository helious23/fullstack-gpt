from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import AsyncChromiumLoader, SitemapLoader
from langchain.document_transformers import Html2TextTransformer
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
import streamlit as st
from bs4 import BeautifulSoup
import html2text

llm = ChatOpenAI(
    temperature=0.1,
)

answers_prompt = ChatPromptTemplate.from_template(
    """
    #ëª…ë ¹ë¬¸
    ë‹¹ì‹ ì€ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ê¸° ì…ë‹ˆë‹¤.
    [context]ì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ [question]ì— ëŒ€ë‹µì„ í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
    ëŒ€ë‹µì€ [context]ì— ë‚˜ì™€ ìˆëŠ” ë‚´ìš©ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•˜ë©° ê¸°ì¡´ì˜ í•™ìŠµëœ ë°ì´í„°ê°€ í¬í•¨ë˜ë©´ ì•ˆë©ë‹ˆë‹¤.
    ëŒ€ë‹µì„ ì°¾ì§€ ëª»í•  ê²½ìš° ì§€ì–´ë‚´ì§€ ë§ê³  ëª¨ë¥´ê² ë‹¤ê³  ëŒ€ë‹µí•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
    
    #ì œì•½ì¡°ê±´
    ëŒ€ë‹µì„ ë§Œë“  ê²½ìš° 0ì ì—ì„œ 5ì  ì‚¬ì´ì˜ ìì—°ìˆ˜ë¡œ ëŒ€ë‹µì— ëŒ€í•œ Scoreë¥¼ ë¶€ì—¬í•´ì•¼ í•©ë‹ˆë‹¤.
    ScoreëŠ” ì‚¬ìš©ìì˜ [question]ê³¼ ê´€ë ¨ì´ í´ìˆ˜ë¡ ë†’ê³ , ê´€ë ¨ì´ ì—†ì„ìˆ˜ë¡ ë‚®ì•„ì•¼ í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ [question]ê³¼ ì „í˜€ ìƒê´€ì´ ì—†ëŠ” ë‚´ìš©ì¼ ê²½ìš° ScoreëŠ” 0ì ì…ë‹ˆë‹¤.
    ëª¨ë“  ëŒ€ë‹µì— ë°˜ë“œì‹œ Scoreë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
    Context:{context}
    
    #ì˜ˆì‹œ
    Question: ë‹¬ì€ ì§€êµ¬ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆë‚˜ìš”?
    Answer: ë‹¬ì€ ì§€êµ¬ë¡œë¶€í„° 384,000km ë–¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
    Score: 5
    
    Question: íƒœì–‘ì€ ì§€êµ¬ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆë‚˜ìš”?
    Answer: ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
    Score: 0
    
    ì‹œì‘í•˜ì„¸ìš”!
    
    Question:{question}
    
    """
)


def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    answers_chain = answers_prompt | llm
    # answers = []
    # for doc in docs:
    #     result = answers_chain.invoke(
    #         {
    #             "question": question,
    #             "context": doc.page_content,
    #         }
    #     )
    #     answers.append(result.content)

    return {
        "question": question,
        "answers": [
            {
                "answer": answers_chain.invoke(
                    {
                        "question": question,
                        "context": doc.page_content,
                    }
                ).content,
                "source": doc.metadata["source"],
                "date": doc.metadata["lastmod"],
            }
            for doc in docs
        ],
    }


choose_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            #ëª…ë ¹ë¬¸
            ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ [question]ì— ëŒ€ë‹µì„ í•˜ëŠ” ì„œë¹„ìŠ¤ ì…ë‹ˆë‹¤.
            ì œê³µë˜ëŠ” [answers] ë§Œì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ë‹µì„ í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
            
            #ì œì•½ì¡°ê±´
            ì œê³µë˜ëŠ” [answers] ì¤‘ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ í•­ëª©ê³¼ ê°€ì¥ ìµœê·¼ [Date] í•­ëª©ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ë‹µí•˜ì„¸ìš”.
            ê°€ì¥ ìµœê·¼ì˜ í•­ëª©ë³´ë‹¤ ì ìˆ˜ê°€ ë†’ì€ í•­ëª©ì„ ìš°ì„  ì‚¬ìš©í•˜ì—¬ ëŒ€ë‹µí•˜ì„¸ìš”.
            ì œê³µë˜ëŠ” [answers] ì˜ ì ìˆ˜ê°€ ê°™ì€ í•­ëª©ì´ ìˆë‹¤ë©´, ìµœê·¼ì˜ í•­ëª©ë§Œ ì‚¬ìš©í•˜ì—¬ ëŒ€ë‹µí•˜ì„¸ìš”.
            ì œê³µë˜ëŠ” [answers] ì˜ source ë¥¼ í•¨ê»˜ ë³´ì—¬ì£¼ì„¸ìš”.
            
            ì‹œì‘í•˜ì„¸ìš”!
            Answers: {answers}
         
            """,
        ),
        ("human", "{question}"),
    ]
)


def choose_answer(inputs):
    answers = inputs["answers"]
    question = inputs["question"]
    choose_chain = choose_prompt | llm
    condensed = "\n\n".join(
        f"{answer['answer']} \n Source:{answer['source']} \n Date:{answer['date']}\n"
        for answer in answers
    )
    return choose_chain.invoke(
        {
            "question": question,
            "answers": condensed,
        }
    )


def parse_page(soup: BeautifulSoup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
    if footer:
        footer.decompose()
    return (
        str(soup.get_text())
        .replace("\n", " ")
        .replace("\xa0", " ")
        .replace("CloseSearch Submit Blog", "")
    )


@st.cache_data(
    show_spinner="ì›¹ì‚¬ì´íŠ¸ë¥¼ ì½ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì€ ìµœì´ˆ 1íšŒë§Œ ì§„í–‰ë©ë‹ˆë‹¤."
)
def load_website(url):
    cache_dir = LocalFileStore(f"./.cache/site_embeddings/{url}")
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000, chunk_overlap=200
    )
    loader = SitemapLoader(
        url,
        restrict_to_same_domain=False,
        # filter_urls=[
        #     r"^(.*\/blog\/).*",
        # ],
        parsing_function=parse_page,
    )
    loader.requests_per_second = 1
    loader.requests_kwargs = {"verify": False}
    docs = loader.load_and_split(text_splitter=splitter)
    embeddings = OpenAIEmbeddings()
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)
    vector_store = FAISS.from_documents(docs, cached_embeddings)
    return vector_store.as_retriever()


st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸŒ",
)

st.title("SiteGPT")

html2text_tramsformer = Html2TextTransformer()


with st.sidebar:
    url = st.text_input(
        "URL ì£¼ì†Œë¥¼ ì ì–´ì£¼ì„¸ìš”",
        placeholder="https://example.com/sitemap.xml",
    )

# if url:
#     loader = AsyncChromiumLoader([url])
#     docs = loader.load()
#     st.write(docs)
#     html2text_tramsformer.transform_documents(docs)
#     text_maker = html2text.HTML2Text()
#     text = text_maker.handle(
#         docs[0].page_content,
#     )
#     st.write(text)


if url:
    if ".xml" not in url:
        with st.sidebar:
            st.error("Sitemap URL ì„ ì ì–´ì£¼ì„¸ìš”")
    else:
        retriever = load_website(url)
        query = st.text_input("ì›¹ ì‚¬ì´íŠ¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”")
        if query:
            chain = (
                {
                    "docs": retriever,
                    "question": RunnablePassthrough(),
                }
                | RunnableLambda(get_answers)
                | RunnableLambda(choose_answer)
            )

            result = chain.invoke(query)
            st.markdown(result.content.replace("$", "\$"))

else:
    st.markdown(
        """
        Ask questions about the content of a website.
        
        Start by writing the URL of the website on the sidebar.
        """
    )
